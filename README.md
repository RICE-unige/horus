<div align="center"><a href="https://rice.dibris.unige.it/"> 

| <img src="imgs/horus_logo.jpg" width="20%" height="%" title="HORUS" alt="HORUS"> </a></div> | <h3>Holistic Operational Reality for Unified Systems</h3> |
| :------------------------------------------------------------------------------------------ | :-------------------------------------------------------: |

---

## ğŸ“š Table of Contents
- [ğŸ“š Table of Contents](#-table-of-contents)
- [ğŸ” Overview](#-overview)
  - [**Current Version:** `0.0.1`](#current-version-001)
- [ğŸŒŸ Features](#-features)
- [ğŸ›  Installation](#-installation)
- [ğŸ® Usage](#-usage)
  - [Prerequisites](#prerequisites)
  - [Setup](#setup)
  - [Using the HORUS Application](#using-the-horus-application)
- [ğŸš§ Project Roadmap](#-project-roadmap)
  - [Year 1 (Current)](#year-1-current)
  - [Year 2](#year-2)
  - [Year 3](#year-3)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“ License](#-license)
- [ğŸ“¬ Contact](#-contact)
- [ğŸ’¡ Acknowledgments](#-acknowledgments)
  - [Developed by](#developed-by)
---

<a name="overview"></a>

## ğŸ” Overview

HORUS (**Holistic Operational Reality for Unified Systems**) is an innovative Mixed Reality (MR) application developed for the Meta Quest 3 headset. It provides a comprehensive solution for managing teams of heterogeneous robots in various environments, particularly disaster scenarios.

### **Current Version:** `0.0.1`  
This initial release focuses on teleoperation capabilities for wheeled robots (**ROSbots**). Future updates will support heterogeneous robot teams, including legged (**Spot**) and aerial robots (**Airvolute** and **DJI Tello**).

---

<a name="features"></a>

## ğŸŒŸ Features

- ğŸ¥½ **Mixed reality interface** for robot control and team management.
- ğŸ¤– **Multi-robot task allocation** and management.
- ğŸ“¡ **Real-time sensor data visualization.**
- âœ‹ **Gesture-based controls** for intuitive robot interaction.
- ğŸš— **Teleoperation Modes**:
  - Minimap (Ground Station) Mode
  - Semi-Immersive Mode
  - Full Immersion Mode
- ğŸ¥ Flexible camera visualization.
- ğŸ§‘â€ğŸ’» **Optimized for Meta Quest 3 headset.**

---

<a name="installation"></a>

## ğŸ›  Installation

1. Download the latest APK from the [Releases](https://github.com/RICE-unige/horus/releases) section.
2. Install the APK on your Meta Quest 3 headset using SideQuest or your preferred method for sideloading apps.

> [!TIP]  
> Need help with sideloading? Check out the [Meta Support Documentation](https://www.meta.com/help).

---

<a name="usage"></a>

## ğŸ® Usage

<a name="prerequisites"></a>
### Prerequisites
1. Install the **HORUS Bridge** application on your laptop, where the ROS master will be launched. Visit the [HORUS Bridge GitHub repository](https://github.com/Omotoye/horus_bridge) for installation instructions.
2. Ensure that both your laptop running HORUS Bridge and the Meta Quest 3 headset are on the same network.

<a name="setup"></a>
### Setup
1. Launch the **HORUS Bridge** on your laptop following the instructions in the HORUS Bridge README.
2. Set up and connect all robots for the interface. Instructions are provided in the [HORUS Bridge repository](https://github.com/Omotoye/horus_bridge).

<a name="using-the-horus-application"></a>
### Using the HORUS Application
1. Put on your **Meta Quest 3 headset**.
2. Navigate to your installed apps and launch HORUS.
3. Enter the IP address displayed in the **HORUS Bridge log** (on your laptop) into the HORUS application login page.
4. **Start Managing Robots**:
   - Draw a workspace in the MR environment to create a minimap.
   - Use the minimap to:
     - View robot status.
     - Visualize sensor data.
     - Allocate tasks.
     - Initiate teleoperation.
5. **Teleoperation Modes**:
   - ğŸ—º **Minimap Mode**: Navigate robots using a 2D overhead view.
   - ğŸ¥ **Semi-Immersive Mode**: View robot camera feeds on a virtual large screen.
   - ğŸ” **Full Immersion Mode**: Experience a direct video feed from the robot's front camera.

---

<a name="project-roadmap"></a>

## ğŸš§ Project Roadmap

### Year 1 (Current)  
- âœ… Develop core HORUS interface in Unity.  
- âœ… Implement teleoperation modes for wheeled robots.  
- â¬œ Complete multi-robot management for wheeled robots.  
- â¬œ Conduct initial user testing and refine the interface.  

### Year 2  
- â¬œ Extend support for legged (**Spot**) and aerial (**Airvolute**, **DJI Tello**) robots.  
- â¬œ Implement advanced trajectory planning and debugging tools.  
- â¬œ Develop multi-operator functionality.  
- â¬œ Integrate an AI copilot system for operator assistance.  

### Year 3  
- â¬œ Develop and implement collaborative strategies for heterogeneous robot teams.  
- â¬œ Conduct extensive experimental validation.  
- â¬œ Optimize the system based on experimental results.  
- â¬œ Open-source the HORUS application and release an SDK.  

---

<a name="contributing"></a>

## ğŸ¤ Contributing

We welcome contributions to the HORUS project! Please read our [Contributing Guidelines](CONTRIBUTING.md) for more information on how to get started.

> [!NOTE]  
> Contributions can include new features, bug fixes, and documentation improvements.

---

<a name="license"></a>

## ğŸ“ License

This project is licensed under the Apache License 2.0. See the [LICENSE](LICENSE) file for details.

---

<a name="contact"></a>

## ğŸ“¬ Contact

For questions or support, please contact:
- **[Omotoye Shamsudeen Adekoya](https://rubrica.unige.it/personale/UkFEXVhg)**  
  -  Email: omotoye.adekoya@edu.unige.it  

---

<a name="acknowledgments"></a>

## ğŸ’¡ Acknowledgments

This project is part of a PhD research at the **University of Genoa**, under the supervision of:  
- **[Prof. Carmine Recchiuto](https://rubrica.unige.it/personale/UkNDWV1r)**  
- **[Prof. Antonio Sgorbissa](https://rubrica.unige.it/personale/UkNHWlJp)**  

---

### Developed by  
[RICE Lab](https://rice.dibris.unige.it/) <img src="imgs/rice_lab_logo.png" width="20"/> at the [University of Genoa](https://unige.it/en) <img src="imgs/unige.png" width="15"/>  
 